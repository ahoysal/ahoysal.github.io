<html>

<head>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
</head>

<body>
    <div class="container">
        <h1>Panther</h1>
        <div style="text-align: center;">(CS184 Summer 2025 Homework 3 Write-Up)</div><br>
        <div style="text-align: center;">~ Aagrim Hoysal ~</div>
        <div style="text-align: center;">
            <a href="https://ahoysal.github.io/cs184/panther">Loop Link</a> |
            <a href="https://github.com/cal-cs184/hw-pathtracer-updated-panther" target="_blank">GitHub Repo</a>
        </div>

        <!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

        <h2>Overview</h2>
        WIP

        <h2>Ray Generation and Scene Intersection (Part 1)</h2>
        <h3>From Pixel to World: Generating Rays</h3>
        The basics of a path tracer are sending out rays and finding out what they hit. Thus, we need to find a way to
        generate rays from the camera in the direction of each pixel on the screen. Since we start with an \((x, y)\)
        coordinate in terms of pixels, we can make the rendering resolution agnostic by converting the pixel coordinate
        into a normalized image space with \((0, 0)\) being the bottom left of the image and \((1,1)\) being the top
        right by dividing by pixel by the screen resolution. By normalizing the image space, we can then convert from
        image space into camera space through shifting and scaling the \([0, 1)\) normalized image space range on both
        the x and y axes to \([-\tan(\frac{\text{fov}}{2}), \tan(\frac{\text{fov}}{2}))\), with a separate horizontal
        and vertical \(\text{fov}\) used on each axis. In addition, since image space is in 2D and camera space is in
        3D, we add a standard -1 for the Z axis, since by convention all points on the image plane in camera space are
        on \(z = -1\).
        <br><br>
        This coordinate directly gives us the direction of the ray, since it is at the location of the pixel coordinate
        on the image in camera space and the camera (and by extension the origin of the ray) is at \(0, 0\) in camera
        space. The vector from the camera to our pixel's transformed coordinates is then the transformed value minus the
        origin, which is just the transformed value. Finally, because we know the ray originates at the camera, all we
        need to do to convert from the ray in camera space to world space is simply apply the rotation matrix of the
        camera to rotate the ray in conjunction with the camera. Since vectors (as opposed to points) aren’t affected by
        translations, we don't need to worry about translations or homogenous coordinates, and we can just apply the
        rotation matrix. The transformed vector now gives us a vector pointing in the direction from the camera origin
        to the pixel's coordinates on the image plane in world space. This vector normalized, along with the camera’s
        position in world space serving as the ray's origin, defines a ray going through a specified pixel in world
        space. We can also add some randomness by peturbing the ray by a random amount between \([0,1)\)in the \(x\) and
        \(y\) directions while in pixel space to sample different directions within the same pixel.
        <br><br>
        <h3>Yielding for triangles</h3>
        <figure style="float: inline-end;">
            <img src="images/yield.png" width="200px">
            <figcaption>Rays must yield to triangles!</figcaption>
        </figure>
        If we can find where rays and objects intersect, we can figure out what rays hit. For simplicity, I only
        implemented triangle-ray intersections and sphere-ray intersections. Triangle ray intersections are easily found
        by using the barycentric definition of a plane by defining all points on a plane as the weighted average of the
        three vertices of a triangle, where all weights add up to one (see <a
            href="https://ahoysal.github.io/cs184/rasterization/#part4">earlier explanation of barycentric
            coordinates</a>). By substituting the equation for all points on a ray (defined as \(O_{rigin} +
        D_{irection}t\) for \(t \ge 0\)) as a point, we can solve for the ray and plane's intersection.
        \[
        O - v_0 = \beta (v_1 - v_0) + \gamma (v_2 - v_0) - Dt
        \equiv
        \begin{cases}
        p = O + Dt & \text{Ray equation} \\
        p = (1-\beta-\gamma) v_0 + \beta v_1 + \gamma v_2 & \text{Barycentric plane}
        \end{cases}
        \]
        This lends itself to an elegant matrix:
        \[
        \begin{bmatrix}
        -D & v_1-v_0 & v_2-v_0
        \end{bmatrix}
        \begin{bmatrix}
        t \\ \beta \\ \gamma
        \end{bmatrix}
        =
        O - v_0
        \]
        We can <a href="https://cs184.eecs.berkeley.edu/su25/assets/discussions/06-sol.pdf">solve for \(t, \beta,
            \gamma\) using Cramer's rule</a>, giving us the intersection point on the triangle's plane in barycentric
        coordinates. Then, by checking if the values of \(\alpha (= 1 - \beta - \gamma), \beta, \gamma \ge 0\), we can
        tell if the intersection is within the triangle or not. This process is called the Möller-Trumbore intersection
        algorithm.
        <br><br>
        By using Möller-Trumbore, we get some intersection data for free. The \(t\) value serves as distance along the
        ray, and so lets us cut values too close or far from the camera and prevent intersecting occluded objects by
        only taking the closest distance. The barycentric coordinates can be used to interpolate between assigned normal
        vectors for each vertex on the triangle to give a normal at the intersection point as well.
        <h3>Stopping when Spheres are Near</h3>
        Sphere intersections follow the same basic method, but instead substituting the ray equation into an implicitly
        defined sphere. Defining the sphere's center as \(c\),
        \[
        \begin{cases}
        p = O + Dt & \text{Ray equation} \\
        r^2 = (x-c_x)^2 + (y-c_y)^2 + (z-c_z)^2 = \sum_{1}^{3} (p[i] - c[i])^2 & \text{Implicit Sphere}
        \end{cases}
        \]
        This can be formed into a quadratic equation:
        \[
        0 = -r^2 + \sum_{1}^{3} (O[i] + D[i]t - c[i])^2
        \equiv
        0 = (O^2 - 2O\cdot C + C^2 - r^2) + 2D\cdot(O-C)t + D^2t^2
        \]

        <figure style="float: inline-end;">
            <img src="images/yields.png" width="200px">
            <figcaption>I don't think the joke<br>works in this context...</figcaption>
        </figure>
        Which gives us zero roots (no intersection), one root (ray is tangent), or two roots (ray passing through the
        sphere). We can then compare \(t\) values in the same way as we did for triangles to only check the nearest
        intersections. Spheres also give the ability to compute perfect normals by computing the normalized vector from
        the sphere's origin to the intersection point (which we can find by plugging in the computed \(t\) value into
        the original ray equation).

<!--
        <h2>Part 2: Bounding Volume Hierarchy</h2>
        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
        magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
        consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
        pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est
        laborum.

        <h2>Part 3: Direct Illumination</h2>
        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
        magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
        consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
        pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est
        laborum.

        <h2>Part 4: Global Illumination</h2>
        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
        magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
        consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
        pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est
        laborum.

        <h2>Part 5: Adaptive Sampling</h2>
        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
        magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
        consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
        pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est
        laborum.

        <h2>(Optional) Part 6: Extra Credit Opportunities</h2>
        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
        magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
        consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
        pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est
        laborum.

        <h2>Additional Notes (please remove)</h2>
        <ul>
            <li>You can also add code if you'd like as so: <code>code code code</code></li>
            <li>If you'd like to add math equations,
                <ul>
                    <li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
                    <li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
                </ul>
            </li>
        </ul>
        <p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is
            a column in that row. You might find this useful for framing and showing your result images in an organized
            fashion.</p>
        <div style="display: flex; flex-direction: column; align-items: center;">
            <table style="width: 100%; text-align: center; border-collapse: collapse;">
                <tr>
                    <td style="text-align: center;">
                        <img src="cornell.png" width="400px" />
                        <figcaption>Caption goes here.</figcaption>
                    </td>
                    <td style="text-align: center;">
                        <img src="cornell.png" width="400px" />
                        <figcaption>Caption goes here.</figcaption>
                    </td>
                </tr>
                <tr>
                    <td style="text-align: center;">
                        <img src="cornell.png" width="400px" />
                        <figcaption>Caption goes here.</figcaption>
                    </td>
                    <td style="text-align: center;">
                        <img src="cornell.png" width="400px" />
                        <figcaption>Caption goes here.</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        -->
    </div>


    <footer>
        Webpage based off <a href="https://github.com/cal-cs184/hw-webpage" target="_blank">CS 184 homework write up
            template</a>
    </footer>

</body>

</html>